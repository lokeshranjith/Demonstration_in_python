{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e672d224",
   "metadata": {},
   "source": [
    "### Q1Backpropagation:\n",
    "\n",
    "Backpropagation is a fundamental algorithm used to train neural networks by adjusting their weights to minimize a chosen loss function. It's based on the chain rule of calculus and allows us to compute the gradient of the loss function with respect to each weight in the network. This gradient indicates how much changing a particular weight would affect the overall error.\n",
    "     \n",
    "**The process involves two main steps:**\n",
    "\n",
    "* Forward pass: During the forward pass, input data is fed through the network, and activations are computed for each layer, culminating in the output prediction.\n",
    "* Backward pass: In the backward pass, the error between the predicted output and the actual target is calculated using a loss function. The gradient of the loss function with respect to each weight in the network is then computed by propagating the error backward through the network using the chain rule.\n",
    "* Once the gradients are known, the weights are updated using an optimization algorithm such as stochastic gradient descent (SGD) or its variants, adjusting them in a direction that minimizes the loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b55bbb",
   "metadata": {},
   "source": [
    "### Q2.How does a neural network learn:\n",
    "\n",
    "* Neural networks learn through an iterative process called training, where they adjust their weights based on the error between their predictions and the true labels in the training data.\n",
    "* During training, the network makes predictions for the input data, computes the loss (difference between predicted and true values), and adjusts its weights to minimize this loss using backpropagation.\n",
    "* This process is repeated for multiple iterations (epochs), gradually refining the weights of the network to improve its performance on the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cfe07",
   "metadata": {},
   "source": [
    "### Q3.Weight and bias:\n",
    "\n",
    "* In an artificial neural network, weights represent the strength of connections between neurons. They determine the importance of one neuron's output on another. Larger weights amplify the effect of the corresponding inputs, while smaller weights reduce their impact.\n",
    "* Biases are additional parameters added to neurons that allow them to shift the activation function's output vertically, affecting the decision boundary of the network. Biases provide flexibility to the model and help in better fitting the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19b532",
   "metadata": {},
   "source": [
    "### Q4.How does weight work:\n",
    "\n",
    "* Weights in a neural network play a crucial role in determining the network's behavior and predictive power. They are adjusted during the training process to minimize the error between the predicted output and the true labels.\n",
    "* Larger weights indicate stronger connections between neurons, meaning that the input from a neuron with a larger weight has a greater impact on the output of the following neuron.\n",
    "* During training, the weights are updated based on the error calculated through backpropagation. Weights that contribute more to reducing the error are adjusted more, while those that contribute less are adjusted less.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08847bd",
   "metadata": {},
   "source": [
    "### Q5.Effects of learning rate:\n",
    "\n",
    "* The learning rate is a hyperparameter that determines the size of the step taken during the weight update process in gradient-based optimization algorithms like SGD.\n",
    "* If the learning rate is too low, the training process may progress very slowly, as the updates to the weights are too small to make significant progress in reducing the error. This can lead to slow convergence and longer training times.\n",
    "* Conversely, if the learning rate is too high, the updates to the weights may be too large, causing the training process to oscillate or diverge. This results in unstable or poor performance of the neural network.\n",
    "* Choosing an appropriate learning rate is crucial for effective training. Techniques such as learning rate schedules or adaptive learning rate methods can be used to dynamically adjust the learning rate during training based on the network's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ee980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
